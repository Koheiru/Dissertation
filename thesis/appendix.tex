\appendix
%%% Оформление заголовков приложений ближе к ГОСТ:
\setlength{\midchapskip}{20pt}
\renewcommand*{\afterchapternum}{\par\nobreak\vskip \midchapskip}
\renewcommand\thechapter{\Asbuk{chapter}} % Чтобы приложения русскими буквами нумеровались


%==============================================================================
%                Свидетельство о регистрации программы для ЭВМ
%==============================================================================
\chapter{Свидетельство о регистрации программы для ЭВМ} \label{appendix:programm_registration}
\begin{figure}[ht]
    \framebox{\includegraphics[width=0.9\textwidth]{program_registration_no2015660380}}
\end{figure}


%==============================================================================
%                Постановка задачи анализа независимых компонент
%==============================================================================
\chapter{Постановка задачи анализа независимых компонент} \label{appendix:ica_description}

Рассматривая постановку задачи анализа независимых компонент в стационарном случае, предположим существование скрытого случайного вектора $\vector{s}_{m \times 1}$, для которого характерно следующее:
\begin{itemize}
    \item компоненты статистически независимы: $\forall\, i,j\ P(\vector{s}_{i}, \vector{s}_{j}) = P(\vector{s}_{i}) P(\vector{s}_{j})$;
    \item компоненты центрированы: $\forall\, i\ \expectation{\vector{s}_{i}} = 0$;
    \item нормальное распределение имеет не более одной компоненты (в противном случае, согласно центральной предельной теореме, их разделение будет проблематично): $\nexists\, i,j:\ \vector{s}_{i} \sim N\left(0, \sigma_{i}\right), \vector{s}_{j} \sim N\left(0, \sigma_{j}\right)$.
\end{itemize}
В этом случае вектор $\vector{s}$ называется вектором независимых компонент, а его элементы $\vector{s}_{i}$ --- независимыми компонентами. Далее предположим, что наблюдаемый случайный вектор $\vector{x}_{n \times 1}$ является результатом смешения компонент вектора $\vector{s}$, \ie: $$\vector{x} = f_{\theta}(\vector{s}) + \vector{\varepsilon},$$ где $f_{\theta}$ --- неизвестная функция смешивания, зависящая от вектора параметров $\theta$, и $\varepsilon \sim N\left(0, \text{diag}\left(\Sigma\right)\right)$ --- нормально распределённая случайная переменная с нулевым математическим ожиданием и дисперсией $\Sigma$, которая отражает вклад шума в наблюдаемый случайный вектор. Тогда решением задачи будет являться нахождение по выборке наблюдаемого случайного вектора $\vector{x}$ обратной функции $F_{\theta}$, такой что: $$\vector{s} = F_{\theta}(\vector{x})$$. Как следствие, для любой реализации наблюдаемого вектора $\vector{x}$ будет возможно восстановление значений соответствующих ему независимых компонент $\vector{s}_{i}$, \ie мы получим способ проецирования наблюдаемых векторов в пространство, направление осей в котором обеспечивают свойство взаимной статистической независимости компонент векторов.

В линейном случае формулировка задачи приобретает следующий вид: $\vector{x} = \matrix{A} \vector{s} + \varepsilon,$ где $\matrix{A}_{n \times m}$ --- матрица смешивания независимых компонент вектора $\vector{s}$. Решением задачи в этом случае будет нахождение обратной матрицы $\matrix{W}$ (а в случае, когда $m > n$, псевдо обратной матрицы), такой что: $\vector{s} = \matrix{W} \vector{x}.$

